{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "\n",
    "### Feature Rescaling\n",
    "\n",
    "* Normalization: Convert the range of a variable: $x_{new}=\\frac{x_{old}-MIN}{MAX-MIN}$\n",
    "* Standardization:  $x_{new}=\\frac{x_{old}-\\bar{x}}{\\sigma}$\n",
    "\n",
    "\n",
    "\n",
    "### Missing Value Imputation\n",
    "\n",
    "* Remove row\n",
    "* Use mean of the value fo the feature to replace the NA\n",
    "* Use rest of data to predict value\n",
    "\n",
    "### Imbalanced Data\n",
    "\n",
    "* Oversampling: Make multiple copies of the examples of the underepresented class.\n",
    "* Undersampling: Remove randomly examples of the majority class.\n",
    "* Synthetic Creation: Take two (or $k$) examples of the underepresented class, and build an element in-between.\n",
    "\n",
    "\n",
    "### Feature reduction\n",
    "\n",
    "Having too many features can be harmful for the classifier. This is called course of dimensionality (adding more features, keeping the same amount of data, is useful in the beginning, but at some point adding more features will hurt the performance of the model). Reducing the data is useful for:\n",
    "\n",
    "* Remove redundant (correlated) features;\n",
    "* Reduce irrelevant (noise) data\n",
    "\n",
    "Some feature reduction methods are:\n",
    "\n",
    "* Filter methods:\n",
    "  * Select the variables with the most correlation with the target variable.\n",
    "  * Select the variables with the most Information gain.\n",
    "  * Others (Linear discriminant analysis, ANOVA, chi-square (for categorical classifiers))\n",
    "\n",
    "* Wrapper methods\n",
    "  * Step Forward selection: Use a greed method to select features as follows:\n",
    "\n",
    "    1. The set of features $F$ is initialized as empty.\n",
    "    2. For each feature $f_i$: Evaluate the performance of the model with the set of features $F+f_i$\n",
    "    3. Select the $f_i$ that showed the best performance and add it to $F$\n",
    "    4. Go to step 2 until selecting the desired amount of features\n",
    "\n",
    "  * Step Backward selection: Perform the inverse of step forward selection. Start with all the features and gradually discard them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    " \n",
    "- | TRUE (predicted) | FALSE (predicted)\n",
    "--- | --- | ---\n",
    "TRUE (actual)\t| TP | FN\n",
    "FALSE (actual) \t| FP | TN\n",
    "\n",
    "\n",
    "\n",
    "When errors are equally important:\n",
    "\n",
    "* Accuracy: $\\frac{TP+TN}{TP+TN+FP+FN}$. \n",
    "\n",
    "When they are not, multiply the confusion matrix by a cost matrix, or use other metrics:\n",
    "\n",
    "* Precision: $\\frac{TP}{TP+FP}$.  Proportion of relevant cases retrieved (from the total retrieved)\n",
    "* Recall: $\\frac{TP}{TP+FN}$.  Proportion of relevant cases retrieved (from the total relevants)\n",
    "* F1-score: $2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$ Weighted average score of the precision and recall.\n",
    "\n",
    "### Area Under Curve (AUC)\n",
    "\n",
    "Area under the ROC (Receiver Operating Characteristic) Curve is also used to choose a classifier. It is used with those classifiers that retrieve some probability score (and a threshold is used to determine whether it is positive or negative class).\n",
    "\n",
    "The first step is to normalize by the actual class (by row in our example) by computing:\n",
    "\n",
    "* True positive rate: $TPR=\\frac{TP}{TP+FN}$\n",
    "* False positive rate: $FPR=\\frac{FP}{FP+TN}$\n",
    "\n",
    "We plot the values of TPR and FPR using different thresholds.\n",
    "\n",
    "The higher the area under the curve, the better the classifier is.\n",
    "\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "\n",
    "Cross-validation (or rotation estimation, or out-of-sample testing) is a way of estimating the quality model. It consist of dividing the training data in k-fold, and use $k-1$ for train and 1 fold to validate. This is repeated $k$ times using each validation fold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Tune\n",
    "\n",
    "\n",
    "### Regularization\n",
    "The fitting procedure of a linear regression $f(x)=\\beta_0 + \\beta_1x_1 + ...+ \\beta_nx_n$ involves a loss function called as residual sum of squares (RSS) defined as as $RSS=\\sum_{i=1}^{n} (y_i - f(x_i))^2$\n",
    "\n",
    "In order to prevent overfitting a penalty is added (regularization):\n",
    "\n",
    "* L1 (Lasso): $RSS + \\lambda \\sum_{i=1}^{n} |\\beta_i |$\n",
    "* L2 (Ridge): $RSS + \\lambda \\sum_{i=1}^{n} \\beta_i^2$\n",
    "\n",
    "The value of $\\lambda$ is used to decide how much we want to penalize.\n",
    "\n",
    "For more info check [here](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a) and [here](https://github.com/ShuaiW/data-science-question-answer#l1-vs-l2-regularization)\n",
    "\n",
    "### Ensemble Techniques\n",
    "\n",
    "This involves performing samples from the data, train several model and combine:\n",
    "\n",
    "* Bagging (in parallel): Obtain $k$ samples, train $k$ models (in parallel). The result will be the average (or majority vote). \n",
    "* Boosting (sequential): Obtain one sample, train a model and classify. Increase the probability of missclassified instances to be picked in following samples. Repeat $k$ times.\n",
    "* Stacking: Build models that use the output of other models as one of the features.\n",
    "\n",
    "For more info check [here](https://www.pluralsight.com/guides/ensemble-methods:-bagging-versus-boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "Inspired by biological neural networks, Artificial Neural Network are computing systems that are made up of interconnected processing elements (perceptrons). The networks receive a series of inputs $x_1 , x_2 ..., x_n$ (or a vector $X \\in \\mathbb{R}^n$). These inputs are processed by perceptrons and then an output $y_1 , y_2 ..., y_m$ (or a vector $Y \\in \\mathbb{R}^m$) is produced.\n",
    "\n",
    "In order to train a neural network pairs of $(X, Y)$ are provided. Given an input $X$, each perceptron modify their output so the generated output of the network is as similar as possible to $Y$. \n",
    "\n",
    "After the training, when a new unseen input $X'$ is provided, the network produce the estimated class $\\tilde{Y}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The perceptron\n",
    "\n",
    "The perceptron applies a weighted sum of the inputs, apply activation function and then feeds forward the results. \n",
    "\n",
    "![ANN_perceptron](images/ANN_perceptron.png)\n",
    "\n",
    "\n",
    "The process can be formulated as:\n",
    "\n",
    "$$out=f(\\sum w_ix_i+b)$$\n",
    "\n",
    "The activation function $f$ is a non linear functions. The most popular functions are:\n",
    "* ReLU: $f(x)=max(x,0)$\n",
    "* TanH: $f(x)=tanh(x)$\n",
    "* Sigmoid: $f(x)=\\frac{1}{1+e^{-x}}$\n",
    "\n",
    "During the training, the weights $w_i$ (and the bias $b$) are adjusted so the output approximated the real value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feed-forward Neural Networks\n",
    "\n",
    "The perceptrons can be connected to each other creating a network. Those networks that not form cycles are known as Feed-forward neural network. Often these networks are structured in layers.\n",
    "\n",
    "![ANN_network](images/ANN_network.png)\n",
    "\n",
    "An example of a simple network is the multilayer perceptron in which perceptrons\n",
    "are structured in layers, These layers are classified in three types:\n",
    "* Input Layer: A layer in which the perceptrons receive the input and feed it to\n",
    "the next layer.\n",
    "* Hidden layer (one or several): A layer in which perceptrons gather the inputs from the previous layer (either the input layer or the output of another hidden layer), perform the computations and feed the result to the next layer.\n",
    "* Output Layer: A layer in which perceptrons perform the computations and provide the final output of the function that the network is approximating.\n",
    "\n",
    "As the perceptrons are structured in layers the weights can be represented as $w_{input,perceptron}$ like in the following image:\n",
    "\n",
    "![ANN_color](images/ANN_color.png)\n",
    "\n",
    "The layer can be modeled as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "w_{1a} & w_{2a} & w_{3a} & w_{4a}\\\\ \n",
    "w_{1b} & w_{2b} & w_{3b} & w_{4b}\\\\ \n",
    "w_{1c} & w_{2c} & w_{3c} & w_{4c}\\\\ \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1\\\\ \n",
    "x_2\\\\ \n",
    "x_3\\\\\n",
    "x_4\\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_a\\\\ \n",
    "b_b\\\\ \n",
    "b_c\\\\\n",
    "\\end{bmatrix}\n",
    "\\overset{f}{\\rightarrow}\n",
    "\\begin{bmatrix}\n",
    "y_a\\\\ \n",
    "y_b\\\\ \n",
    "y_c\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "This can be expressed in matrix notation. This means that the function of the layer can be represented as an input $X$ (where each column is an input), and matrix of weights $W$ and the bias as a vector $b$. This can be expressed:\n",
    "\n",
    "$$y=f(WX+b)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Improving Transductive Data Selection Algorithms for Machine Translation](http://doras.dcu.ie/23726/1/thesis_AlbertoPoncelas.pdf)\n",
    "\n",
    "https://www.jeremyjordan.me/intro-to-neural-networks/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
